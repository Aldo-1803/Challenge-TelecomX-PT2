# Telecom X ‚Äì Parte 2: Predicci√≥n de Cancelaci√≥n (Churn)

> **Rol:** Analista Junior de Machine Learning  
> **Objetivo:** Construir un pipeline de ML para predecir la cancelaci√≥n de clientes (*churn*) y proponer acciones de negocio basadas en los factores m√°s influyentes.

---

## üß≠ Resumen del proyecto

- **Problema:** Anticipar qu√© clientes tienen mayor probabilidad de cancelar su servicio en Telecom X.  
- **Output:** Modelos de clasificaci√≥n + an√°lisis interpretativo + recomendaciones de retenci√≥n.  
- **Dataset:** Versi√≥n **limpia** y **estandarizada** de la Parte 1 ‚Üí `datos_tratados.csv` (sin identificadores, columnas relevantes).

---

## ‚öôÔ∏è Requisitos

- Python 3.12.11  
- Librer√≠as principales:  
  `pandas`, `numpy`, `scikit-learn`, `imbalanced-learn`, `matplotlib`, `seaborn`

## üöÄ C√≥mo ejecutar

  1. Colocar data/datos_tratados.csv.
  2. Abrir el notebook notebooks/01_telecomx_parte2_modelado.ipynb.
  3. Ejecutar todas las celdas en orden.

El notebook realiza:

  * Carga de datos tratados.
  * Eliminaci√≥n de columnas irrelevantes (customerid).
  * Separaci√≥n de X (features) y y (target churn).
  * One-Hot Encoding a categ√≥ricas y StandardScaler a num√©ricas (via ColumnTransformer).
  * Verificaci√≥n de balance de clases (‚âà 73% no churn / 27% churn).
  * Opcional: SMOTE para balancear.
  * Train/Test split (70/30, stratify=y).
  * Entrenamiento de Regresi√≥n Log√≠stica y Random Forest.
  * Evaluaci√≥n con Accuracy, Precision, Recall, F1, ROC-AUC y Matriz de Confusi√≥n.
  * Interpretaci√≥n de coeficientes (LR) e importancia de variables (RF).
  * Gr√°ficos comparativos de m√©tricas e importancia de variables.

## üß™ Modelos y evaluaci√≥n

Se entrenaron dos enfoques complementarios:

  * Regresi√≥n Log√≠stica (sensible a escala, interpretable).
  * Random Forest (√°rboles, robusto a escala, no lineal).
    
| Modelo              | Accuracy | Precision (churn) | Recall (churn) | F1 (churn) | ROC-AUC |
| ------------------- | -------: | ----------------: | -------------: | ---------: | ------: |
| Regresi√≥n Log√≠stica |    0.798 |             0.640 |          0.547 |      0.590 |   0.840 |
| Random Forest       |    0.784 |             0.618 |          0.485 |      0.544 |   0.826 |

Lectura recomendada: en churn, priorizar Recall y F1-score de la clase positiva (clientes que cancelan), ya que el costo de no detectarlos es mayor que el de un falso positivo.

## üîç Factores que m√°s influyen

### Regresi√≥n Log√≠stica ‚Äì aumentan el riesgo (coef. +):
- `account_chargestotal` (gasto total)  
- `internet_internetservice_fiber optic`  
- `account_paymentmethod_electronic check`  
- `phone_multiplelines_yes`  
- `account_paperlessbilling`  

### Regresi√≥n Log√≠stica ‚Äì reducen el riesgo (coef. ‚Äì):
- `customer_tenure` (antig√ºedad)  
- `account_contract_two year`  
- `internet_internetservice_no`  
- `account_contract_one year`  
- `internet_techsupport_yes`  

### Random Forest ‚Äì top importancias:
1. `account_chargestotal`  
2. `customer_tenure`  
3. `account_chargesmonthly`  
4. `cuentas_diarias`  
5. `internet_internetservice_fiber optic`  

üìå **Conclusi√≥n interpretativa:**  
El tipo de contrato, la antig√ºedad del cliente y los costos (mensuales/totales), junto con el tipo de servicio de internet y el m√©todo de pago, son los factores m√°s determinantes para predecir la cancelaci√≥n.

---

## ‚öñÔ∏è Balance de clases
- Distribuci√≥n original: ~**73% no churn / 27% churn**.  
- Se ofrece pipeline con **SMOTE** (opcional) para mejorar Recall en la clase minoritaria.  
- Alternativa: `class_weight` en modelos lineales o basados en √°rboles.

---

## üß© Consideraciones de overfitting/underfitting

- **Random Forest:** puede sobreajustarse si no se limitan par√°metros como `max_depth`, `min_samples_leaf`, `n_estimators`, `max_features`.  
- **Regresi√≥n Log√≠stica:** puede subajustar (underfitting) si las relaciones son no lineales o falta ingenier√≠a de variables. Ajustar regularizaci√≥n (`C`) o interacciones de features.

---

## üó∫Ô∏è Roadmap de mejora

- **B√∫squeda de hiperpar√°metros:** `RandomizedSearchCV` / `GridSearchCV`.  
- **M√©tricas costo-sensibles:** AUC-PR; an√°lisis de umbral (curva costo‚Äìbeneficio).  
- **Validaci√≥n:** *k-fold CV* para robustez.  
- **Nuevas features:** estacionalidad, variaci√≥n de cargos, tickets de soporte, morosidad.  
- **Balanceo:** comparar **SMOTE** vs. `class_weight`.

---

## üñºÔ∏è Visualizaciones sugeridas

- Comparativa de m√©tricas por modelo (barras).  
- Matrices de confusi√≥n normalizadas.  
- Importancia de variables (RF).  
- Coeficientes ordenados (LR).  
- Boxplots dirigidos (tenure vs. churn; total charges vs. churn).  

---

## üìÑ Licencia
Este proyecto se distribuye con fines educativos. Ajustar seg√∫n pol√≠ticas del curso/empresa.

---


